# Reinforcement Learning â€“ Assignment 4  
## Multi-Armed Bandits: UCB and Naive Algorithm

---

## ðŸ“Œ Questions

### 1. UCB Comparison
- Compare **UCB** for:
  - Stationary reward distributions
  - Non-stationary reward distributions  
- Include performance plots.
- Also compare:
  - **Constant Î± (step-size)**
  - **Sample Average method**

---

### 2. Naive Algorithm
- Implement the Naive algorithm with:
  - Îµ = 0.1  
  - Î´ = 0.05  

---

### 3. Effect of Îµ and Î´
- Vary:
  - Îµ from 0.01 to 0.1
  - Î´ from 0.01 to 0.1
- Create performance plots to analyze the effect of different values.

---

## ðŸ§  Algorithms

### UCB
UCB selects actions using:

$$
A_t = \arg\max_a \left[ Q_t(a) + c \sqrt{\frac{\ln t}{N_t(a)}} \right]
$$

- Works well in stationary environments.
- In non-stationary settings:
  - Sample Average adapts slowly.
  - Constant Î± performs better.

### Naive Algorithm
Uses empirical means and confidence bounds based on Îµ and Î´ to guide action selection.

---

## ðŸ“Š Analysis
- UCB performs well for stationary rewards.
- Constant step-size is better for non-stationary environments.
- Smaller Îµ and Î´ increase confidence but require more samples.

---

## ðŸš€ How to Run
1. Open `RL_Assignment_4.ipynb`
2. Run all cells
3. Observe generated performance plots.
